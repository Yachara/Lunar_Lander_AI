{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LunarLander-v2 DQN\n",
    "\n",
    "Applying the stuff I already learned to a new enviornment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the 2D enviornments to work:\n",
    "\n",
    "conda install swig\n",
    "\n",
    "pip install Box2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting to know the enviornment\n",
    "\n",
    "Landing pad is always at coordinates (0,0). Coordinates are the first two numbers in state vector. Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points. If lander moves away from landing pad it loses reward back. Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points. Each leg ground contact is +10. Firing main engine is -0.3 points each frame. Solved is 200 points. Landing outside landing pad is possible. Fuel is infinite, so an agent can learn to fly and then land on its first attempt. Action is two real values vector from -1 to +1. First controls main engine, -1..0 off, 0..+1 throttle from 50% to 100% power. Engine can't work with less than 50% power. Second value -1.0..-0.5 fire left engine, +0.5..+1.0 fire right engine, -0.5..0.5 off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prvi uč v dokumentaciji je STATE sledeč:\n",
    "* Pos x\n",
    "* Pos y\n",
    "* Velocity x\n",
    "* Velocity y\n",
    "* self.lander.angle\n",
    "* (something to do with Angular velocity)\n",
    "* 1 if leg0 has ground contact, else 0\n",
    "* 1 if leg1 has ground contact, else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prvi uč so ACTIONS:\n",
    "* 0 -> do nothing\n",
    "* 1 -> right engine\n",
    "* 2 -> main engine\n",
    "* 3 -> left engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from time import time\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env = gym.wrappers.Monitor(env, \"./videos/\"+str(int(time()))+\"/\", video_callable=lambda episode_id: episode_id%100==0)\n",
    "env._max_episode_steps = 20 # changes the max steps in an episode\n",
    "#env.reset()\n",
    "\n",
    "print(\"Observation space: \", env.observation_space.shape)\n",
    "print(\"Action space: \", env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env._max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for episode in range(10):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    print(\"\\n\\nEPISODE: \", episode)\n",
    "    print(\"== State: \", state)\n",
    "    \n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = 2#env.action_space.sample()\n",
    "        #print(\"== Making action: \", action)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "        \n",
    "        if steps >= env._max_episode_steps:\n",
    "            print(\"MAX STEPS\")\n",
    "            done = True\n",
    "            reward = -100\n",
    "            env.stats_recorder.save_complete()\n",
    "            env.stats_recorder.done = True\n",
    "        \n",
    "        print(\"Stats recorder: \", env.stats_recorder.done)\n",
    "        print(\"== Steps: \", steps)\n",
    "        print(f\"== Next state: {next_state}\")\n",
    "        print(f\"== Reward: {reward}\")\n",
    "        print(f\"== Done: {done}\")\n",
    "        #print(f\"== Info: {info}\")\n",
    "        print()\n",
    "        \n",
    "    #print(\"Steps: \", steps)\n",
    "    #print(reward)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "class DQNPlotting:\n",
    "    '''\n",
    "    Class used to graphically present different aspects of DQN Learning.\n",
    "    \n",
    "    One of the things I would like to get a better look into is:\n",
    "        - Which states were most visited\n",
    "        - Which states were most used while training\n",
    "        \n",
    "    Class works by creating Axes. It periodically draws over the Axes or redraws the whole thing.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self):\n",
    "        rows = 1\n",
    "        columns = 2\n",
    "        self.fig, self.ax = plt.subplots(rows, columns, figsize=(15, 10))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def draw(self, graph_data, data_clear=False):\n",
    "        '''\n",
    "        PARAMS\n",
    "            data     <dictionary>   Dictionary, where \"key\" is the axes we want to draw the data. Value is the data we want to plot\n",
    "                                        Example:\n",
    "                                            {(1,2): {\n",
    "                                                \"x\": [1,2,3],\n",
    "                                                \"y\": [4,5,6]\n",
    "                                                }\n",
    "                                                \"draw_mode\": \"scatter\"\n",
    "                                                \"x_label\": \"num_of_episodes\",\n",
    "                                                \"y_label\": \"reward\"\n",
    "                                            }\n",
    "            clear    <boolean>      If True, it will clear the Axes before drawing.\n",
    "        \n",
    "        RETURNS\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        \n",
    "        if data_clear:\n",
    "            print(\"ADD FUNCTIONALITY WHEN WE WANT TO CLEAR AXES\")\n",
    "            pass # TO-DO add the clearing part of code\n",
    "        \n",
    "        for key, value in graph_data.items():\n",
    "            if value[\"draw_mode\"] == \"scatter\":\n",
    "                self.ax[key].scatter(value[\"x\"], value[\"y\"], c=value[\"c\"], alpha=0.005)\n",
    "                self.ax\n",
    "            elif value[\"draw_mode\"] == \"plot\":\n",
    "                self.ax[key].plot(value[\"x\"], value[\"y\"], c=value[\"c\"])\n",
    "            self.ax[key].set_xlabel(value[\"x_label\"])\n",
    "            self.ax[key].set_ylabel(value[\"y_label\"])\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DQNModel:\n",
    "    '''\n",
    "    Class that manages the neural network of DQN agent.\n",
    "    Through it the models parameters are controled:\n",
    "        * number of layers\n",
    "        * nodes in each layer\n",
    "        * activation functions\n",
    "        * optimizers\n",
    "        * etc...\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def create_model(self, input_shape, action_space):\n",
    "        '''\n",
    "        Method used to create the model.\n",
    "        \n",
    "        PARAMS:\n",
    "            input_shape    <integer>    the number of input neurons the network needs\n",
    "            action_space   <integer>    number of output neuron the network needs\n",
    "            \n",
    "        RETURNS:\n",
    "            models    <tensorflow neural network>    this holds the neural network model\n",
    "            \n",
    "        '''\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(512, input_shape=input_shape, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(256, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(64, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(action_space, activation=\"linear\", kernel_initializer='he_uniform'))\n",
    "        \n",
    "        model.compile(loss=\"mse\", optimizer=RMSprop(lr=0.00025, rho=0.95, epsilon=0.01), metrics=['accuracy'])\n",
    "\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "class DQNMemory:\n",
    "    '''\n",
    "    Class used to manage the DQN Memory.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, \n",
    "                 good_memory,\n",
    "                 max_good_episodes = 5, # how many good episodes can be in the good memory\n",
    "                 max_bad_episodes = 5,\n",
    "                 \n",
    "                ):\n",
    "        self.setup_memory(good_memory)\n",
    "        self.max_good_episodes = max_good_episodes\n",
    "        self.max_bad_episodes = max_bad_episodes\n",
    "        \n",
    "        self.moments_gathered = 0 # every moment we add, this gets +1. Its a stand-in for checking when to start training\n",
    "    \n",
    "    \n",
    "    def setup_memory(self, good_memory=None, bad_memory=None):\n",
    "        if good_memory != None:\n",
    "            self.good_memory = good_memory         # Holds a few full episodes in which I won by hand\n",
    "        elif good_memory == None:\n",
    "            self.good_memory = {}\n",
    "        \n",
    "        if bad_memory != None:\n",
    "            self.bad_memory = bad_memory\n",
    "        elif bad_memory == None:\n",
    "            self.bad_memory = {}\n",
    "        \n",
    "        self.random_memory = deque(maxlen=1000) # This will be the random memory from episodes\n",
    "        self.episode_memory = []   # This holds the memory of 1 episode. So that I can save it if we WIN\n",
    "        \n",
    "        self.memory = np.empty(shape=(0,5))\n",
    "    \n",
    "    def add_memory(self, state, action, reward, next_state, done):\n",
    "        '''\n",
    "        Adds a new memory to the overall memory.\n",
    "        \n",
    "        PARAMS:\n",
    "        \n",
    "        RETURNS:\n",
    "        '''\n",
    "        self.random_memory.append(np.array([state, action, reward, next_state, done]))\n",
    "        self.episode_memory.append(np.array([state, action, reward, next_state, done]))\n",
    "        self.moments_gathered += 1\n",
    "        \n",
    "        \n",
    "    def reset_episode_memory(self):\n",
    "        self.episode_memory = []\n",
    "    \n",
    "    \n",
    "    def add_good_episode_to_memory(self, ep_reward):\n",
    "        good_episode = np.array(self.episode_memory)\n",
    "        \n",
    "        print()\n",
    "        print(\"Good episodes: \", list(self.good_memory.keys()), \"/\", self.max_good_episodes)\n",
    "        \n",
    "        if len(self.good_memory.keys()) < self.max_good_episodes:\n",
    "            self.good_memory[ep_reward] = good_episode\n",
    "        elif ep_reward > min(self.good_memory.keys()):\n",
    "            del self.good_memory[min(self.good_memory.keys())]\n",
    "            self.good_memory[ep_reward] = good_episode # tko se nadomesti najmanjši reward z novim episodičnim spominom\n",
    "            \n",
    "    def add_bad_episode_to_memory(self, ep_reward):\n",
    "        bad_episode = np.array(self.episode_memory)\n",
    "        \n",
    "        print(\"Bad episodes: \", list(self.bad_memory.keys()), \"/\", self.max_bad_episodes)\n",
    "\n",
    "        if len(self.bad_memory.keys()) < self.max_bad_episodes:\n",
    "            self.bad_memory[ep_reward] = bad_episode\n",
    "        elif ep_reward < max(self.bad_memory.keys()):\n",
    "            del self.bad_memory[max(self.bad_memory.keys())]\n",
    "            self.bad_memory[ep_reward] = bad_episode # tko se nadomesti najmanjši reward z novim episodičnim spominom\n",
    "            \n",
    "            \n",
    "    def get_minibatch(self, batch_size):\n",
    "        '''\n",
    "        Function that returns a minibatch from the overall memory.\n",
    "        \n",
    "        \n",
    "        \n",
    "        PARAMS:\n",
    "            batch_size    <integer>    the size of the minibatch\n",
    "            \n",
    "        RETURNS:\n",
    "            minibatch     <>\n",
    "        '''\n",
    "        \n",
    "        # Select one of the good_episode from good_memory.\n",
    "        # The higher the total_reward it got, the higher the chances to be choosen\n",
    "        # From that good_episode, get the minibatch\n",
    "        good_rewards = np.array(list(self.good_memory.keys())) # get the good rewards\n",
    "        #normalize the good_rewards to fall between -1 and 1. If they are not normalized than extreme values will fuck with the math..\n",
    "        # normalization can be done on a bigger interval, but -1 to 1 is probably good..\n",
    "        \n",
    "        norm_good_rewards = 2* ((good_rewards-np.min(good_rewards))/(np.max(good_rewards)-np.min(good_rewards))) - 1\n",
    "        good_probabilities = np.exp(norm_good_rewards)/np.sum(np.exp(norm_good_rewards)) # e^x/sum(e^x)\n",
    "        good_probabilities[-1] = 1-sum(good_probabilities[:-1])\n",
    "        good_choice = np.random.choice(good_rewards, 1, p=good_probabilities)[0] # Function returns array, even if with only 1 number\n",
    "        # Get moments from self.good_memory\n",
    "        good_memory = np.empty(shape=(0, 5)) # should not be hardcoded like this\n",
    "        for moment in self.good_memory[good_choice]:\n",
    "            moment = np.reshape(moment, newshape=(1, moment.shape[0]))\n",
    "            good_memory = np.append(good_memory, moment, axis=0)\n",
    "            \n",
    "        # Do the same probabilites for the bad memory\n",
    "        bad_rewards = np.array(list(self.bad_memory.keys()))\n",
    "        # normalize the bad rewards between -1 and 1\n",
    "        norm_bad_rewards = 2* ((bad_rewards-np.min(bad_rewards))/(np.max(bad_rewards)-np.min(bad_rewards))) - 1\n",
    "        bad_probabilities = np.exp(norm_bad_rewards)/np.sum(np.exp(norm_bad_rewards)) # we are taking the best bad_episode (-200, -300, -400) we would take -200.. not really what i wanted but ok. I wanted to take the worst (-400)\n",
    "        bad_probabilities[-1] = 1-sum(bad_probabilities[:-1])\n",
    "        bad_choice = np.random.choice(bad_rewards, 1, p=bad_probabilities)[0] # Function returns array, even if with only 1 number\n",
    "        # Get moments from self.bad_memory\n",
    "        bad_memory = np.empty(shape=(0, 5)) # should not be hardcoded like this\n",
    "        for moment in self.bad_memory[bad_choice]:\n",
    "            moment = np.reshape(moment, newshape=(1, moment.shape[0]))\n",
    "            bad_memory = np.append(bad_memory, moment, axis=0)\n",
    "        \n",
    "        random_memory = np.empty(shape=(0, 5)) # should not be hardcoded like this\n",
    "        random_memory = np.append(random_memory, self.random_memory, axis=0)\n",
    "        \n",
    "        minibatch = np.empty(shape=(0,5)) # should not be hardcoded\n",
    "        \n",
    "        np.random.shuffle(good_memory)\n",
    "        minibatch = np.append(minibatch, good_memory[:int(batch_size/3)], axis=0)\n",
    "        \n",
    "        np.random.shuffle(bad_memory)\n",
    "        minibatch = np.append(minibatch, bad_memory[:int(batch_size/3)], axis=0)\n",
    "        \n",
    "        np.random.shuffle(random_memory)\n",
    "        \n",
    "        minibatch = np.append(minibatch, random_memory[:int(batch_size/3)], axis=0) # We contantly go through good and bad episodes. But there is a WHOLE lot in between. Im guessing.. maybe I don't need this much moments from random memory\n",
    "        \n",
    "        return minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle # for quick saving of memory\n",
    "\n",
    "\n",
    "class DQNAgent:\n",
    "    '''\n",
    "    Class used to manage the DQN Agent.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 state_size,\n",
    "                 action_size,\n",
    "                 good_memory=None,      # I played some rounds to win and get the \"good path\"\n",
    "                 gamma=0.95,         # reward discount rate\n",
    "                 epsilon=1.0,        # exploration rate\n",
    "                 epsilon_min=0.001,\n",
    "                 epsilon_decay=0.999,\n",
    "                 batch_size=64,\n",
    "                 train_start=1000,   # when we have this many individual memories, the training can start\n",
    "                 \n",
    "                ):\n",
    "        '''\n",
    "        \n",
    "        PARAMS:\n",
    "            state_size    <integer>    Defines how many input neurons we need.\n",
    "            action_size   <integer>    How many different actions we can make. Defines how many output neurons we need.\n",
    "            gamma         <float>      The reward discount rate. Value is used in the newQ value calculation.\n",
    "            epsilon       <float>      The exploration. If a random number is lower than epsilon we will make a random action.\n",
    "            epsilon_min   <float>      The minimal value epsilon can take.\n",
    "            epsilon_decay <float>      Value used when decaying the epsilon.\n",
    "            batch_size    <integer>    The size of the minibatch we take from memory when training.\n",
    "            train_start   <integer>    The amount of individual memories we want to have before we start training.\n",
    "            \n",
    "        RETURNS:\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.EPISODES = EPISODES\n",
    "        self.memory = DQNMemory(good_memory=good_memory)\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.train_start = train_start\n",
    "\n",
    "        # create main model\n",
    "        self.model = DQNModel().create_model(input_shape=(self.state_size,), \n",
    "                              action_space = self.action_size)\n",
    "        \n",
    "        \n",
    "    def load(self, path):\n",
    "        '''\n",
    "        Loads the pre-existing model. \n",
    "        (Does the model need to be the same architecture or can it be anything?)\n",
    "        \n",
    "        PARAMS:\n",
    "            path   <string>    path to the model\n",
    "        '''\n",
    "        \n",
    "        self.model = load_model(path)\n",
    "        self.model.summary()\n",
    "\n",
    "\n",
    "    def save(self, path, model_name=None):\n",
    "        '''\n",
    "        Save the neural network model.\n",
    "        \n",
    "        PARAMS:\n",
    "            path    <string>    path where to save the model. The model name is added automaticaly\n",
    "                                Example: path = \"D/DQN/Models/\"\n",
    "        '''\n",
    "        if model_name == None:\n",
    "            model_name = DNQModel().name + \"model.h5\"  # create the model name\n",
    "        \n",
    "        path = os.path.join(path, model_name)\n",
    "        print(\"Saving model under: \", path)\n",
    "        self.model.save(path)\n",
    "        \n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.add_memory(state, action, reward, next_state, done)\n",
    "\n",
    "        \n",
    "    def update_exploring(self):\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "                \n",
    "    def get_action(self, state):\n",
    "        state = np.reshape(state, newshape=(1, state.shape[0]))\n",
    "        q_values = self.model.predict(state) # gets Q-values for each state-action pair\n",
    "        actions = np.argsort(q_values) # Sorts the Q-values from lowest to highest and returns their indexes. \n",
    "        #Example: [3,2,4,1] means that the Q-value on index 3 is the lowest, next one is on index 2, etc.\n",
    "        \n",
    "        #print(\"Q-Values: \", q_values)\n",
    "        if np.random.random() <= self.epsilon:\n",
    "            # We are exploring by taking a second best action (not a random one)\n",
    "            #return random.randrange(self.action_size) # this makes a random action. Which could also be the correct one\n",
    "            \n",
    "            actions = actions[:, :-1] # this gets all EXCEPT the best action.. since we want to explore\n",
    "            #p = (0.2,0.3,0.5) # the distribution when we choose our action... we want the second best to be choosen the most, but we also want to be able to choose the worst one so that we actually do explore\n",
    "            # p should not be so hard-coded\n",
    "            # we want the first action (which has the word Q and is the worst action) to have the lowest probablity to be choosen\n",
    "            # but we still want to choose it some times... \n",
    "            action = np.random.choice(actions.flatten(), 1)[0]\n",
    "            #print(\"Worse choosen: \", action)\n",
    "            return action\n",
    "        else:\n",
    "            action = actions[:, -1][0]\n",
    "            #print(\"Best choosen:\", action)\n",
    "            return action # making the best action\n",
    "\n",
    "        \n",
    "    def train(self, graph):\n",
    "        '''\n",
    "        graph pove nej izrisuje minibatches, da se vid na kerih STATEs se uči\n",
    "        '''\n",
    "        if self.memory.moments_gathered < self.train_start:\n",
    "            return\n",
    "        self.memory.moments_gathered = self.train_start\n",
    "        # Randomly sample minibatch from the memory\n",
    "        minibatch = self.memory.get_minibatch(batch_size=self.batch_size)\n",
    "        '''\n",
    "        Napisat kako točn more minibatch zgledat kt struktura\n",
    "        '''\n",
    "        \n",
    "        # Unpacking the minibatch so we can prepare for training\n",
    "        state = np.empty(shape=(0, self.state_size))\n",
    "        for s in minibatch[:, 0]:\n",
    "            #print(s, s.shape, type(s))\n",
    "            reshaped = np.reshape(s, newshape=(1, s.shape[0]))\n",
    "            #print(reshaped, reshaped.shape)\n",
    "            state = np.append(state, reshaped, axis=0)\n",
    "        action = minibatch[:, 1]\n",
    "        reward = minibatch[:, 2]\n",
    "        next_state = np.empty(shape=(0,self.state_size))\n",
    "        for s in minibatch[:, 3]: # I dont like this for looping. Stuff should be done on the tensor level...\n",
    "            #print(s, s.shape, type(s))\n",
    "            reshaped = np.reshape(s, newshape=(1, s.shape[0]))\n",
    "            #print(reshaped, reshaped.shape)\n",
    "            next_state = np.append(next_state, reshaped, axis=0)\n",
    "        done = minibatch[:, 4]\n",
    "        \n",
    "        # do batch prediction to save speed\n",
    "        target = self.model.predict(state, batch_size=state.shape[0])\n",
    "        target_next = self.model.predict(next_state)\n",
    "        '''\n",
    "        predict() will go through all the data, batch by batch, predicting labels. \n",
    "        It thus internally does the splitting in batches and feeding one batch at a time.\n",
    "\n",
    "        predict_on_batch(), on the other hand, assumes that the data you pass in is exactly \n",
    "        one batch and thus feeds it to the network. It won't try to split it (which, depending on \n",
    "        your setup, might prove problematic for your GPU memory if the array is very big)\n",
    "        '''\n",
    "        \n",
    "        for i in range(reward.shape[0]):\n",
    "            # correction on the Q value for the action used\n",
    "            if done[i]:\n",
    "                target[i][action[i]] = reward[i]\n",
    "            else:\n",
    "                # Standard - DQN\n",
    "                # DQN chooses the max Q value among next actions\n",
    "                # selection and evaluation of action is on the target Q Network\n",
    "                # Q_max = max_a' Q_target(s', a')\n",
    "                target[i][action[i]] = reward[i] + self.gamma * (np.amax(target_next[i]))\n",
    "        \n",
    "        if graph != None:\n",
    "            graph_data = {\n",
    "                (2,): {\n",
    "                    \"x\": [x[0] for x in state],\n",
    "                    \"y\": [x[1] for x in state],\n",
    "                    \"draw_mode\": \"scatter\",\n",
    "                    \"x_label\": \"position\",\n",
    "                    \"y_label\": \"velocity\",\n",
    "                }\n",
    "            }\n",
    "            graph.draw(graph_data)\n",
    "        # Train the Neural Network with batches\n",
    "        self.model.fit(state, target, batch_size=self.batch_size, verbose=0)\n",
    "        \n",
    "        \n",
    "        def save_memory(self):\n",
    "            with open(\"good_memory.pickle\", \"wb\") as f:\n",
    "                pickle.dump(self.memory.good_memory, f)\n",
    "            with open(\"good_memory.pickle\", \"wb\") as f:\n",
    "                pickle.dump(self.memory.bad_memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env,\n",
    "        agent,\n",
    "        EPISODES,\n",
    "        render_every_ep,\n",
    "        graph,\n",
    "       ):\n",
    "    \n",
    "    scores = [0,]\n",
    "    try:\n",
    "        for episode in range(EPISODES):\n",
    "            state = env.reset()\n",
    "            agent.memory.reset_episode_memory()\n",
    "            done = False\n",
    "            total_reward = 0\n",
    "            steps = 0\n",
    "            \n",
    "            while not done:\n",
    "                if episode%render_every_ep==0:\n",
    "                    env.render()              \n",
    "                    \n",
    "                action = agent.get_action(state)\n",
    "                if graph != None:\n",
    "                    '''\n",
    "                    graph_data = {\n",
    "                        (0,): {\n",
    "                            \"x\": state[0][0],\n",
    "                            \"y\": state[0][1],\n",
    "                            \"draw_mode\": \"scatter\",\n",
    "                            \"x_label\": \"position\",\n",
    "                            \"y_label\": \"velocity\",\n",
    "                        },\n",
    "                    }\n",
    "                    graph.draw(graph_data)\n",
    "                    '''\n",
    "                    pass\n",
    "\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                steps += 1\n",
    "                \n",
    "                if steps >= env._max_episode_steps:\n",
    "                    '''\n",
    "                    Need to manualy implement since Wrappers does not end when it reached _max_episode_steps\n",
    "                    '''\n",
    "                    #print(\"MAX STEPS\")\n",
    "                    env.stats_recorder.save_complete()\n",
    "                    env.stats_recorder.done = True\n",
    "                    reward = -100\n",
    "                    pass\n",
    "                    \n",
    "                total_reward += reward\n",
    "                \n",
    "                agent.remember(state, action, reward, next_state, done)\n",
    "                state = next_state\n",
    "                \n",
    "                agent.train(graph)\n",
    "                \n",
    "                \n",
    "            agent.update_exploring() # it makes more sense to change exploring after 1 whole episode is passed\n",
    "            agent.memory.add_good_episode_to_memory(total_reward)\n",
    "            agent.memory.add_bad_episode_to_memory(total_reward)\n",
    "            # add episode to good and bad every time. If it has medium reward it goes to noone, else it goes to either bad or good\n",
    "            scores.append(total_reward)\n",
    "            \n",
    "            \n",
    "            we_won_str = \"!! WINNER, WE WON !!\" if reward == 100 else \"\"\n",
    "            print(f\"Ep: {episode}/{EPISODES}, Total_RWD: {total_reward:.1f}, Steps: {steps}/{env._max_episode_steps} e: {agent.epsilon:.2f}, Last_rwd: {reward}, {we_won_str}\")                 \n",
    "            \n",
    "            \n",
    "            if episode%50==0:\n",
    "                model_name = f\"DQN_T{int(time())}_E{episode}.h5\"  # Naming convention is: DQN_<time>_<additional information>\n",
    "                agent.save(path=\"./models/\", model_name=model_name)\n",
    "                with open(\"good_memory.pickle\", \"wb\") as f:\n",
    "                    pickle.dump(good_episodes, f)\n",
    "                pass\n",
    "            \n",
    "            if graph != None:\n",
    "                episode_moments = [moment[0] for moment in agent.memory.episode_memory]\n",
    "                graph_data = {\n",
    "                    (0,): {\n",
    "                        \"x\": [state[0][0] for state in episode_moments],\n",
    "                        \"y\": [state[0][1] for state in episode_moments],\n",
    "                        \"draw_mode\": \"scatter\",\n",
    "                        \"x_label\": \"position\",\n",
    "                        \"y_label\": \"velocity\",\n",
    "                    },\n",
    "                    (1,): {\n",
    "                        \"x\": [episode-1, episode],\n",
    "                        \"y\": scores[-2:],\n",
    "                        \"draw_mode\": \"plot\",\n",
    "                        \"x_label\": \"episode num\",\n",
    "                        \"y_label\": \"episode reward\"\n",
    "                    }\n",
    "                }\n",
    "                graph.draw(graph_data)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"KeyboardInterrupt\")\n",
    "    except Exception as e:\n",
    "        print(\"ERROR\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        env.close()\n",
    "        return scores                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               4608      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 152,644\n",
      "Trainable params: 152,644\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Good episodes:  [] / 3\n",
      "Bad episodes:  [] / 3\n",
      "Ep: 0/1000, Total_RWD: -444.3, Steps: 90/4000 e: 0.30, Last_rwd: -100, \n",
      "Saving model under:  ./models/DQN_T1604787640_E0.h5\n",
      "\n",
      "Good episodes:  [-444.29159775503746] / 3\n",
      "Bad episodes:  [-444.29159775503746] / 3\n",
      "Ep: 1/1000, Total_RWD: -464.8, Steps: 78/4000 e: 0.29, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-444.29159775503746, -464.7524806668263] / 3\n",
      "Bad episodes:  [-444.29159775503746, -464.7524806668263] / 3\n",
      "Ep: 2/1000, Total_RWD: -331.9, Steps: 60/4000 e: 0.29, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-444.29159775503746, -464.7524806668263, -331.8954725384192] / 3\n",
      "Bad episodes:  [-444.29159775503746, -464.7524806668263, -331.8954725384192] / 3\n",
      "Ep: 3/1000, Total_RWD: -486.3, Steps: 75/4000 e: 0.29, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-444.29159775503746, -464.7524806668263, -331.8954725384192] / 3\n",
      "Bad episodes:  [-444.29159775503746, -464.7524806668263, -486.26126216245234] / 3\n",
      "Ep: 4/1000, Total_RWD: -346.8, Steps: 91/4000 e: 0.29, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-444.29159775503746, -331.8954725384192, -346.75567641567505] / 3\n",
      "Bad episodes:  [-444.29159775503746, -464.7524806668263, -486.26126216245234] / 3\n",
      "Ep: 5/1000, Total_RWD: -256.9, Steps: 52/4000 e: 0.28, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-331.8954725384192, -346.75567641567505, -256.93680007121793] / 3\n",
      "Bad episodes:  [-444.29159775503746, -464.7524806668263, -486.26126216245234] / 3\n",
      "Ep: 6/1000, Total_RWD: -498.3, Steps: 85/4000 e: 0.28, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-331.8954725384192, -346.75567641567505, -256.93680007121793] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 7/1000, Total_RWD: -432.0, Steps: 62/4000 e: 0.28, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-331.8954725384192, -346.75567641567505, -256.93680007121793] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 8/1000, Total_RWD: -210.7, Steps: 59/4000 e: 0.27, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-331.8954725384192, -256.93680007121793, -210.71904745173907] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 9/1000, Total_RWD: -173.6, Steps: 82/4000 e: 0.27, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-256.93680007121793, -210.71904745173907, -173.6206849895674] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 10/1000, Total_RWD: -317.9, Steps: 150/4000 e: 0.27, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-256.93680007121793, -210.71904745173907, -173.6206849895674] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 11/1000, Total_RWD: -83.0, Steps: 105/4000 e: 0.27, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-210.71904745173907, -173.6206849895674, -83.03189207485849] / 3\n",
      "Bad episodes:  [-464.7524806668263, -486.26126216245234, -498.28305292912825] / 3\n",
      "Ep: 12/1000, Total_RWD: -817.0, Steps: 193/4000 e: 0.26, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-210.71904745173907, -173.6206849895674, -83.03189207485849] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 13/1000, Total_RWD: -248.3, Steps: 104/4000 e: 0.26, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-210.71904745173907, -173.6206849895674, -83.03189207485849] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 14/1000, Total_RWD: -138.0, Steps: 105/4000 e: 0.26, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-173.6206849895674, -83.03189207485849, -137.96756390529262] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 15/1000, Total_RWD: -297.7, Steps: 187/4000 e: 0.26, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-173.6206849895674, -83.03189207485849, -137.96756390529262] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 16/1000, Total_RWD: -139.3, Steps: 151/4000 e: 0.25, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, -137.96756390529262, -139.29069826841288] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 17/1000, Total_RWD: -208.3, Steps: 157/4000 e: 0.25, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, -137.96756390529262, -139.29069826841288] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 18/1000, Total_RWD: -143.0, Steps: 183/4000 e: 0.25, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, -137.96756390529262, -139.29069826841288] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 19/1000, Total_RWD: -274.3, Steps: 284/4000 e: 0.25, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, -137.96756390529262, -139.29069826841288] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 20/1000, Total_RWD: 103.7, Steps: 1000/4000 e: 0.24, Last_rwd: 1.2717080671224466, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, -137.96756390529262, 103.68060042421845] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 21/1000, Total_RWD: -114.9, Steps: 242/4000 e: 0.24, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -114.87021580725512] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 22/1000, Total_RWD: -320.8, Steps: 183/4000 e: 0.24, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -114.87021580725512] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 23/1000, Total_RWD: -210.5, Steps: 233/4000 e: 0.24, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -114.87021580725512] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 24/1000, Total_RWD: -180.8, Steps: 277/4000 e: 0.23, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -114.87021580725512] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 25/1000, Total_RWD: -178.5, Steps: 277/4000 e: 0.23, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -114.87021580725512] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 26/1000, Total_RWD: -66.4, Steps: 1000/4000 e: 0.23, Last_rwd: -0.008337226409064147, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -66.4496110666992] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 27/1000, Total_RWD: -337.1, Steps: 869/4000 e: 0.23, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [-83.03189207485849, 103.68060042421845, -66.4496110666992] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 28/1000, Total_RWD: -14.8, Steps: 470/4000 e: 0.22, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 29/1000, Total_RWD: -160.2, Steps: 353/4000 e: 0.22, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 30/1000, Total_RWD: -223.7, Steps: 520/4000 e: 0.22, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 31/1000, Total_RWD: -129.0, Steps: 212/4000 e: 0.22, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 32/1000, Total_RWD: -132.7, Steps: 483/4000 e: 0.22, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 33/1000, Total_RWD: -68.3, Steps: 358/4000 e: 0.21, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -66.4496110666992, -14.846653598220357] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 34/1000, Total_RWD: -59.2, Steps: 304/4000 e: 0.21, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -59.15492295502685] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 35/1000, Total_RWD: -54.8, Steps: 558/4000 e: 0.21, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -54.77420227802742] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 36/1000, Total_RWD: -32.9, Steps: 220/4000 e: 0.21, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -32.880353783455135] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 37/1000, Total_RWD: -78.9, Steps: 344/4000 e: 0.20, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -32.880353783455135] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 38/1000, Total_RWD: -71.6, Steps: 247/4000 e: 0.20, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -32.880353783455135] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 39/1000, Total_RWD: -232.3, Steps: 157/4000 e: 0.20, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, -32.880353783455135] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 40/1000, Total_RWD: 20.8, Steps: 417/4000 e: 0.20, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, 20.822452027660773] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 41/1000, Total_RWD: -98.5, Steps: 251/4000 e: 0.20, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, 20.822452027660773] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 42/1000, Total_RWD: -135.4, Steps: 708/4000 e: 0.19, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, 20.822452027660773] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 43/1000, Total_RWD: -44.2, Steps: 1000/4000 e: 0.19, Last_rwd: 0.9716739765669871, \n",
      "\n",
      "Good episodes:  [103.68060042421845, -14.846653598220357, 20.822452027660773] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 44/1000, Total_RWD: 7.9, Steps: 1000/4000 e: 0.19, Last_rwd: 0.9248102656038253, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 7.85315633479384] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 45/1000, Total_RWD: 129.8, Steps: 1000/4000 e: 0.19, Last_rwd: -0.4302481801584406, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 46/1000, Total_RWD: -92.9, Steps: 174/4000 e: 0.19, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 47/1000, Total_RWD: -74.9, Steps: 127/4000 e: 0.19, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 48/1000, Total_RWD: -69.5, Steps: 333/4000 e: 0.18, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 49/1000, Total_RWD: -39.0, Steps: 253/4000 e: 0.18, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 50/1000, Total_RWD: -56.5, Steps: 1000/4000 e: 0.18, Last_rwd: -0.38046218407832444, \n",
      "Saving model under:  ./models/DQN_T1604790621_E50.h5\n",
      "\n",
      "Good episodes:  [103.68060042421845, 20.822452027660773, 129.78510344011602] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 51/1000, Total_RWD: 130.4, Steps: 1000/4000 e: 0.18, Last_rwd: 0.5709475260738301, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 52/1000, Total_RWD: -55.9, Steps: 1000/4000 e: 0.18, Last_rwd: -2.8810125660082933, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 53/1000, Total_RWD: -22.3, Steps: 1000/4000 e: 0.17, Last_rwd: 10.343546960545435, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 54/1000, Total_RWD: -109.4, Steps: 547/4000 e: 0.17, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 55/1000, Total_RWD: -108.2, Steps: 266/4000 e: 0.17, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 56/1000, Total_RWD: -143.5, Steps: 211/4000 e: 0.17, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 57/1000, Total_RWD: -115.8, Steps: 225/4000 e: 0.17, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 58/1000, Total_RWD: -78.1, Steps: 230/4000 e: 0.17, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 59/1000, Total_RWD: -178.5, Steps: 156/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 60/1000, Total_RWD: -172.4, Steps: 114/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 61/1000, Total_RWD: -164.3, Steps: 176/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 62/1000, Total_RWD: -164.0, Steps: 142/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 63/1000, Total_RWD: -177.2, Steps: 100/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 64/1000, Total_RWD: -119.8, Steps: 107/4000 e: 0.16, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 65/1000, Total_RWD: -132.0, Steps: 1000/4000 e: 0.15, Last_rwd: -0.9702546368617948, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 66/1000, Total_RWD: -217.7, Steps: 166/4000 e: 0.15, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 67/1000, Total_RWD: 87.3, Steps: 1000/4000 e: 0.15, Last_rwd: 0.06767001944885465, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 68/1000, Total_RWD: -225.1, Steps: 123/4000 e: 0.15, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [103.68060042421845, 129.78510344011602, 130.42713882353775] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 69/1000, Total_RWD: 125.6, Steps: 1000/4000 e: 0.15, Last_rwd: -0.18156359502895647, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 70/1000, Total_RWD: -55.4, Steps: 399/4000 e: 0.15, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 71/1000, Total_RWD: 72.1, Steps: 1000/4000 e: 0.15, Last_rwd: -0.09669337617462759, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 72/1000, Total_RWD: -17.0, Steps: 296/4000 e: 0.14, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 73/1000, Total_RWD: 109.7, Steps: 1000/4000 e: 0.14, Last_rwd: 0.038086389760147554, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 74/1000, Total_RWD: 119.3, Steps: 1000/4000 e: 0.14, Last_rwd: -17.573195188914795, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 75/1000, Total_RWD: 92.6, Steps: 1000/4000 e: 0.14, Last_rwd: -0.22243966995574027, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 76/1000, Total_RWD: 113.5, Steps: 1000/4000 e: 0.14, Last_rwd: 0.5547287435752697, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 77/1000, Total_RWD: 108.0, Steps: 1000/4000 e: 0.14, Last_rwd: 11.06519102066496, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 125.63190994556358] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 78/1000, Total_RWD: 239.0, Steps: 566/4000 e: 0.14, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 238.96534436810697] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 79/1000, Total_RWD: 5.8, Steps: 1000/4000 e: 0.13, Last_rwd: -0.008430293668949956, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 238.96534436810697] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 80/1000, Total_RWD: 106.9, Steps: 1000/4000 e: 0.13, Last_rwd: 0.5469038690943187, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 238.96534436810697] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 81/1000, Total_RWD: 97.1, Steps: 1000/4000 e: 0.13, Last_rwd: 0.48460334894730295, \n",
      "\n",
      "Good episodes:  [129.78510344011602, 130.42713882353775, 238.96534436810697] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 82/1000, Total_RWD: 189.6, Steps: 891/4000 e: 0.13, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [130.42713882353775, 238.96534436810697, 189.57431652534305] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 83/1000, Total_RWD: 127.4, Steps: 1000/4000 e: 0.13, Last_rwd: -0.6589557305651172, \n",
      "\n",
      "Good episodes:  [130.42713882353775, 238.96534436810697, 189.57431652534305] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 84/1000, Total_RWD: -26.5, Steps: 129/4000 e: 0.13, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [130.42713882353775, 238.96534436810697, 189.57431652534305] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 85/1000, Total_RWD: 183.0, Steps: 620/4000 e: 0.13, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [238.96534436810697, 189.57431652534305, 182.993820233883] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 86/1000, Total_RWD: 44.8, Steps: 1000/4000 e: 0.13, Last_rwd: -0.04903909324451547, \n",
      "\n",
      "Good episodes:  [238.96534436810697, 189.57431652534305, 182.993820233883] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 87/1000, Total_RWD: -231.9, Steps: 175/4000 e: 0.12, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [238.96534436810697, 189.57431652534305, 182.993820233883] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 88/1000, Total_RWD: 265.3, Steps: 558/4000 e: 0.12, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [238.96534436810697, 189.57431652534305, 265.29419564765453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 89/1000, Total_RWD: -59.3, Steps: 265/4000 e: 0.12, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [238.96534436810697, 189.57431652534305, 265.29419564765453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 90/1000, Total_RWD: 218.2, Steps: 939/4000 e: 0.12, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [238.96534436810697, 265.29419564765453, 218.19192951938686] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 91/1000, Total_RWD: 252.1, Steps: 570/4000 e: 0.12, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [238.96534436810697, 265.29419564765453, 252.115414835596] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 92/1000, Total_RWD: 217.7, Steps: 607/4000 e: 0.12, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [238.96534436810697, 265.29419564765453, 252.115414835596] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 93/1000, Total_RWD: 241.4, Steps: 912/4000 e: 0.12, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 241.40720121832527] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 94/1000, Total_RWD: 140.9, Steps: 1000/4000 e: 0.12, Last_rwd: 0.13071848938578867, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 241.40720121832527] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 95/1000, Total_RWD: 110.0, Steps: 1000/4000 e: 0.11, Last_rwd: -0.1940800572443304, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 241.40720121832527] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 96/1000, Total_RWD: 237.3, Steps: 783/4000 e: 0.11, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 241.40720121832527] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 97/1000, Total_RWD: 272.4, Steps: 368/4000 e: 0.11, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 272.38588789239276] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 98/1000, Total_RWD: 210.2, Steps: 633/4000 e: 0.11, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 272.38588789239276] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 99/1000, Total_RWD: -22.8, Steps: 139/4000 e: 0.11, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 272.38588789239276] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 100/1000, Total_RWD: -2.4, Steps: 280/4000 e: 0.11, Last_rwd: -100, \n",
      "Saving model under:  ./models/DQN_T1604796024_E100.h5\n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 272.38588789239276] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 101/1000, Total_RWD: 18.6, Steps: 183/4000 e: 0.11, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 252.115414835596, 272.38588789239276] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 102/1000, Total_RWD: 265.7, Steps: 381/4000 e: 0.11, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 103/1000, Total_RWD: 258.1, Steps: 389/4000 e: 0.11, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 104/1000, Total_RWD: 252.1, Steps: 365/4000 e: 0.10, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 105/1000, Total_RWD: 223.5, Steps: 476/4000 e: 0.10, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 106/1000, Total_RWD: 193.9, Steps: 515/4000 e: 0.10, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 107/1000, Total_RWD: 34.7, Steps: 110/4000 e: 0.10, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 108/1000, Total_RWD: 134.4, Steps: 1000/4000 e: 0.10, Last_rwd: -0.05531503309104899, \n",
      "\n",
      "Good episodes:  [265.29419564765453, 272.38588789239276, 265.69880155926825] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 109/1000, Total_RWD: 278.6, Steps: 354/4000 e: 0.10, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 110/1000, Total_RWD: -68.5, Steps: 217/4000 e: 0.10, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 111/1000, Total_RWD: -49.6, Steps: 200/4000 e: 0.10, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 112/1000, Total_RWD: 219.9, Steps: 643/4000 e: 0.10, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 113/1000, Total_RWD: -83.5, Steps: 135/4000 e: 0.10, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 114/1000, Total_RWD: 265.7, Steps: 411/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 115/1000, Total_RWD: -71.1, Steps: 371/4000 e: 0.09, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 116/1000, Total_RWD: 165.6, Steps: 756/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 265.69880155926825, 278.5962263427549] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 117/1000, Total_RWD: 271.3, Steps: 686/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 271.3466325549301] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 118/1000, Total_RWD: 228.1, Steps: 564/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 271.3466325549301] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 119/1000, Total_RWD: 232.0, Steps: 405/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 271.3466325549301] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 120/1000, Total_RWD: 208.4, Steps: 586/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 271.3466325549301] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 121/1000, Total_RWD: 133.7, Steps: 786/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 271.3466325549301] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 122/1000, Total_RWD: 296.3, Steps: 330/4000 e: 0.09, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 123/1000, Total_RWD: -14.6, Steps: 210/4000 e: 0.09, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 124/1000, Total_RWD: -2.0, Steps: 223/4000 e: 0.09, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 125/1000, Total_RWD: -9.1, Steps: 171/4000 e: 0.08, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 126/1000, Total_RWD: 210.4, Steps: 486/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 127/1000, Total_RWD: 2.9, Steps: 213/4000 e: 0.08, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 128/1000, Total_RWD: 117.4, Steps: 1000/4000 e: 0.08, Last_rwd: -0.40267609279323824, \n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 129/1000, Total_RWD: 268.1, Steps: 320/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 130/1000, Total_RWD: 189.7, Steps: 557/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 131/1000, Total_RWD: 203.0, Steps: 838/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 132/1000, Total_RWD: 220.9, Steps: 676/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 133/1000, Total_RWD: 237.3, Steps: 346/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [272.38588789239276, 278.5962263427549, 296.3041177248857] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 134/1000, Total_RWD: 282.0, Steps: 295/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 135/1000, Total_RWD: -64.6, Steps: 208/4000 e: 0.08, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 136/1000, Total_RWD: 222.6, Steps: 417/4000 e: 0.08, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 137/1000, Total_RWD: -19.3, Steps: 223/4000 e: 0.07, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 138/1000, Total_RWD: 16.9, Steps: 317/4000 e: 0.07, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 139/1000, Total_RWD: 213.4, Steps: 802/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 140/1000, Total_RWD: 153.7, Steps: 1000/4000 e: 0.07, Last_rwd: -0.0006427957704246978, \n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 141/1000, Total_RWD: 258.1, Steps: 374/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 142/1000, Total_RWD: 221.2, Steps: 456/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 143/1000, Total_RWD: 189.2, Steps: 594/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 144/1000, Total_RWD: 228.3, Steps: 432/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 145/1000, Total_RWD: 236.4, Steps: 306/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 146/1000, Total_RWD: 110.1, Steps: 1000/4000 e: 0.07, Last_rwd: 0.49240044850812836, \n",
      "\n",
      "Good episodes:  [278.5962263427549, 296.3041177248857, 282.02635277660136] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 147/1000, Total_RWD: 289.2, Steps: 728/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 148/1000, Total_RWD: 260.8, Steps: 374/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 149/1000, Total_RWD: -66.5, Steps: 204/4000 e: 0.07, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 150/1000, Total_RWD: 256.4, Steps: 278/4000 e: 0.07, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "Saving model under:  ./models/DQN_T1604799743_E150.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 151/1000, Total_RWD: -54.1, Steps: 139/4000 e: 0.07, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 152/1000, Total_RWD: 269.7, Steps: 423/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 153/1000, Total_RWD: 256.2, Steps: 445/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 154/1000, Total_RWD: -450.4, Steps: 146/4000 e: 0.06, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 155/1000, Total_RWD: -23.9, Steps: 348/4000 e: 0.06, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 156/1000, Total_RWD: 215.4, Steps: 485/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 157/1000, Total_RWD: 224.5, Steps: 728/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 158/1000, Total_RWD: 130.4, Steps: 879/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 159/1000, Total_RWD: -26.7, Steps: 437/4000 e: 0.06, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 160/1000, Total_RWD: 213.9, Steps: 552/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 161/1000, Total_RWD: 245.2, Steps: 372/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 282.02635277660136, 289.1602845740319] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 162/1000, Total_RWD: 294.6, Steps: 406/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 163/1000, Total_RWD: 242.7, Steps: 507/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 164/1000, Total_RWD: 261.9, Steps: 435/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 165/1000, Total_RWD: 222.6, Steps: 458/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 166/1000, Total_RWD: 229.8, Steps: 505/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 167/1000, Total_RWD: 219.4, Steps: 484/4000 e: 0.06, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 168/1000, Total_RWD: -2.1, Steps: 135/4000 e: 0.05, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 169/1000, Total_RWD: 276.9, Steps: 462/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 170/1000, Total_RWD: 11.5, Steps: 168/4000 e: 0.05, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 289.1602845740319, 294.59616694176134] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 171/1000, Total_RWD: 290.4, Steps: 258/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 290.4164625906019] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 172/1000, Total_RWD: 174.5, Steps: 913/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 290.4164625906019] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 173/1000, Total_RWD: 295.5, Steps: 368/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 174/1000, Total_RWD: 290.3, Steps: 317/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 175/1000, Total_RWD: 256.6, Steps: 279/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 176/1000, Total_RWD: 226.6, Steps: 367/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 177/1000, Total_RWD: -32.0, Steps: 283/4000 e: 0.05, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 178/1000, Total_RWD: 238.2, Steps: 367/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 179/1000, Total_RWD: 230.8, Steps: 468/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 180/1000, Total_RWD: 278.5, Steps: 295/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 181/1000, Total_RWD: 241.2, Steps: 282/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 182/1000, Total_RWD: 257.1, Steps: 751/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 183/1000, Total_RWD: 251.3, Steps: 323/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 184/1000, Total_RWD: 251.7, Steps: 739/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 185/1000, Total_RWD: 224.5, Steps: 373/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 186/1000, Total_RWD: 245.9, Steps: 871/4000 e: 0.05, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 187/1000, Total_RWD: -3.4, Steps: 104/4000 e: 0.05, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 188/1000, Total_RWD: 263.5, Steps: 241/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 189/1000, Total_RWD: 235.2, Steps: 398/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 190/1000, Total_RWD: 241.4, Steps: 500/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 191/1000, Total_RWD: 241.0, Steps: 918/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 192/1000, Total_RWD: 274.1, Steps: 260/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 193/1000, Total_RWD: 162.5, Steps: 809/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 194/1000, Total_RWD: -7.4, Steps: 113/4000 e: 0.04, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 195/1000, Total_RWD: 261.7, Steps: 306/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 196/1000, Total_RWD: 265.8, Steps: 451/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 197/1000, Total_RWD: 272.2, Steps: 302/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 198/1000, Total_RWD: 259.9, Steps: 354/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 199/1000, Total_RWD: 231.3, Steps: 334/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 200/1000, Total_RWD: -1.5, Steps: 218/4000 e: 0.04, Last_rwd: -100, \n",
      "Saving model under:  ./models/DQN_T1604803156_E200.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 201/1000, Total_RWD: 269.1, Steps: 824/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 202/1000, Total_RWD: 280.0, Steps: 333/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 203/1000, Total_RWD: 232.7, Steps: 325/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 204/1000, Total_RWD: 251.8, Steps: 281/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 205/1000, Total_RWD: 251.1, Steps: 415/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 206/1000, Total_RWD: 284.8, Steps: 251/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 207/1000, Total_RWD: 257.5, Steps: 438/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 208/1000, Total_RWD: 213.4, Steps: 526/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 209/1000, Total_RWD: 259.6, Steps: 423/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 210/1000, Total_RWD: 265.7, Steps: 309/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 211/1000, Total_RWD: 270.9, Steps: 260/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 212/1000, Total_RWD: 215.2, Steps: 505/4000 e: 0.04, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 213/1000, Total_RWD: 229.1, Steps: 327/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 214/1000, Total_RWD: 6.6, Steps: 183/4000 e: 0.03, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 215/1000, Total_RWD: 249.6, Steps: 391/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 216/1000, Total_RWD: 253.1, Steps: 363/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 217/1000, Total_RWD: 223.8, Steps: 713/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 218/1000, Total_RWD: 227.8, Steps: 437/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 219/1000, Total_RWD: 272.4, Steps: 238/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 220/1000, Total_RWD: 254.9, Steps: 385/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 221/1000, Total_RWD: 264.8, Steps: 349/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 222/1000, Total_RWD: 248.7, Steps: 415/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 223/1000, Total_RWD: 248.2, Steps: 413/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 224/1000, Total_RWD: 262.1, Steps: 301/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 225/1000, Total_RWD: 228.8, Steps: 292/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 226/1000, Total_RWD: 266.8, Steps: 328/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 227/1000, Total_RWD: -23.8, Steps: 98/4000 e: 0.03, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 228/1000, Total_RWD: 269.2, Steps: 513/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 229/1000, Total_RWD: 186.2, Steps: 857/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 230/1000, Total_RWD: 209.6, Steps: 743/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 231/1000, Total_RWD: 7.3, Steps: 523/4000 e: 0.03, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 232/1000, Total_RWD: 247.6, Steps: 300/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 233/1000, Total_RWD: 245.2, Steps: 512/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 234/1000, Total_RWD: 282.6, Steps: 300/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 235/1000, Total_RWD: 271.0, Steps: 529/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 236/1000, Total_RWD: 241.8, Steps: 382/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 237/1000, Total_RWD: -299.1, Steps: 108/4000 e: 0.03, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 238/1000, Total_RWD: -57.8, Steps: 113/4000 e: 0.03, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 239/1000, Total_RWD: 269.6, Steps: 293/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 240/1000, Total_RWD: 267.4, Steps: 341/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 241/1000, Total_RWD: 248.2, Steps: 274/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 242/1000, Total_RWD: 254.7, Steps: 405/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 243/1000, Total_RWD: 279.7, Steps: 368/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 244/1000, Total_RWD: 282.8, Steps: 268/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 245/1000, Total_RWD: 175.7, Steps: 439/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 246/1000, Total_RWD: 199.4, Steps: 581/4000 e: 0.03, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 247/1000, Total_RWD: 272.8, Steps: 345/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 248/1000, Total_RWD: 210.8, Steps: 588/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 249/1000, Total_RWD: 274.3, Steps: 460/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 250/1000, Total_RWD: 228.4, Steps: 536/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "Saving model under:  ./models/DQN_T1604806422_E250.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 251/1000, Total_RWD: -324.4, Steps: 218/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 252/1000, Total_RWD: 285.1, Steps: 480/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 253/1000, Total_RWD: 121.5, Steps: 754/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 254/1000, Total_RWD: 123.5, Steps: 1000/4000 e: 0.02, Last_rwd: -0.006248807538288048, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 255/1000, Total_RWD: 252.7, Steps: 345/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 256/1000, Total_RWD: -106.9, Steps: 544/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 257/1000, Total_RWD: -304.5, Steps: 88/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 258/1000, Total_RWD: -337.4, Steps: 63/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 259/1000, Total_RWD: 195.0, Steps: 529/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-486.26126216245234, -498.28305292912825, -816.9901736818529] / 3\n",
      "Ep: 260/1000, Total_RWD: -501.9, Steps: 62/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-498.28305292912825, -816.9901736818529, -501.8627770571693] / 3\n",
      "Ep: 261/1000, Total_RWD: -765.4, Steps: 82/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -501.8627770571693, -765.3636957610377] / 3\n",
      "Ep: 262/1000, Total_RWD: -622.3, Steps: 85/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -622.286963272584] / 3\n",
      "Ep: 263/1000, Total_RWD: -48.9, Steps: 125/4000 e: 0.02, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -622.286963272584] / 3\n",
      "Ep: 264/1000, Total_RWD: -416.4, Steps: 58/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -622.286963272584] / 3\n",
      "Ep: 265/1000, Total_RWD: -555.2, Steps: 72/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -622.286963272584] / 3\n",
      "Ep: 266/1000, Total_RWD: -381.2, Steps: 50/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -622.286963272584] / 3\n",
      "Ep: 267/1000, Total_RWD: -804.8, Steps: 98/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -804.8006650518284] / 3\n",
      "Ep: 268/1000, Total_RWD: -336.0, Steps: 108/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -765.3636957610377, -804.8006650518284] / 3\n",
      "Ep: 269/1000, Total_RWD: -1635.1, Steps: 289/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -804.8006650518284, -1635.0678242133074] / 3\n",
      "Ep: 270/1000, Total_RWD: -672.1, Steps: 205/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -804.8006650518284, -1635.0678242133074] / 3\n",
      "Ep: 271/1000, Total_RWD: -443.6, Steps: 153/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -804.8006650518284, -1635.0678242133074] / 3\n",
      "Ep: 272/1000, Total_RWD: -160.5, Steps: 261/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -804.8006650518284, -1635.0678242133074] / 3\n",
      "Ep: 273/1000, Total_RWD: -522.9, Steps: 195/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -804.8006650518284, -1635.0678242133074] / 3\n",
      "Ep: 274/1000, Total_RWD: -1243.0, Steps: 351/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-816.9901736818529, -1635.0678242133074, -1243.0188418614368] / 3\n",
      "Ep: 275/1000, Total_RWD: -1303.7, Steps: 538/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 276/1000, Total_RWD: -276.9, Steps: 189/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 277/1000, Total_RWD: -926.5, Steps: 640/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 278/1000, Total_RWD: 16.5, Steps: 1000/4000 e: 0.02, Last_rwd: -0.34635625874030995, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 279/1000, Total_RWD: -72.6, Steps: 317/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 280/1000, Total_RWD: -34.8, Steps: 1000/4000 e: 0.02, Last_rwd: -0.5306330041831149, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 281/1000, Total_RWD: -26.2, Steps: 1000/4000 e: 0.02, Last_rwd: -0.8205716401109271, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 282/1000, Total_RWD: -15.1, Steps: 1000/4000 e: 0.02, Last_rwd: 2.4990822186468726, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 283/1000, Total_RWD: 61.4, Steps: 1000/4000 e: 0.02, Last_rwd: 0.0693589368618828, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 284/1000, Total_RWD: 265.2, Steps: 448/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 285/1000, Total_RWD: 262.9, Steps: 354/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 286/1000, Total_RWD: 199.3, Steps: 339/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 287/1000, Total_RWD: 261.1, Steps: 370/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 288/1000, Total_RWD: 266.4, Steps: 378/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 289/1000, Total_RWD: 3.3, Steps: 210/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 290/1000, Total_RWD: -10.7, Steps: 85/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 291/1000, Total_RWD: 169.1, Steps: 742/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 292/1000, Total_RWD: 243.2, Steps: 567/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 293/1000, Total_RWD: 25.4, Steps: 1000/4000 e: 0.02, Last_rwd: -0.7052389574226747, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 294/1000, Total_RWD: 145.2, Steps: 857/4000 e: 0.02, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 295/1000, Total_RWD: -94.8, Steps: 397/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 296/1000, Total_RWD: -287.4, Steps: 865/4000 e: 0.02, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 297/1000, Total_RWD: -404.7, Steps: 814/4000 e: 0.02, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 298/1000, Total_RWD: -216.1, Steps: 1000/4000 e: 0.01, Last_rwd: 4.298436457168305, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 299/1000, Total_RWD: 179.4, Steps: 979/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 300/1000, Total_RWD: 233.6, Steps: 583/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "Saving model under:  ./models/DQN_T1604810235_E300.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 301/1000, Total_RWD: 204.6, Steps: 775/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 302/1000, Total_RWD: 231.4, Steps: 486/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 303/1000, Total_RWD: -152.6, Steps: 1000/4000 e: 0.01, Last_rwd: -2.031526566514684, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 304/1000, Total_RWD: -77.0, Steps: 108/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 305/1000, Total_RWD: 248.7, Steps: 293/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 306/1000, Total_RWD: 248.2, Steps: 322/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 307/1000, Total_RWD: 268.7, Steps: 307/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 308/1000, Total_RWD: 220.2, Steps: 332/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 309/1000, Total_RWD: 200.2, Steps: 479/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 310/1000, Total_RWD: 225.3, Steps: 438/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 311/1000, Total_RWD: 229.9, Steps: 453/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 312/1000, Total_RWD: 234.3, Steps: 561/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 313/1000, Total_RWD: 10.1, Steps: 409/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 314/1000, Total_RWD: 154.5, Steps: 693/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 315/1000, Total_RWD: -339.5, Steps: 278/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 316/1000, Total_RWD: 79.9, Steps: 957/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 317/1000, Total_RWD: 273.1, Steps: 414/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 318/1000, Total_RWD: 1.3, Steps: 237/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 319/1000, Total_RWD: 245.3, Steps: 458/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 320/1000, Total_RWD: 274.5, Steps: 324/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 321/1000, Total_RWD: -165.1, Steps: 88/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 322/1000, Total_RWD: 235.1, Steps: 390/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 323/1000, Total_RWD: 207.0, Steps: 340/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 324/1000, Total_RWD: 252.7, Steps: 349/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 325/1000, Total_RWD: -928.0, Steps: 152/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 326/1000, Total_RWD: -447.6, Steps: 143/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 327/1000, Total_RWD: 217.4, Steps: 358/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 328/1000, Total_RWD: 180.8, Steps: 670/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 329/1000, Total_RWD: 176.6, Steps: 502/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 330/1000, Total_RWD: 132.5, Steps: 882/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 331/1000, Total_RWD: -475.7, Steps: 159/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 332/1000, Total_RWD: 209.5, Steps: 463/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 333/1000, Total_RWD: -22.7, Steps: 66/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 334/1000, Total_RWD: -313.8, Steps: 1000/4000 e: 0.01, Last_rwd: -0.7226209306399187, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 335/1000, Total_RWD: -24.8, Steps: 1000/4000 e: 0.01, Last_rwd: 0.34311035669811646, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 336/1000, Total_RWD: -23.9, Steps: 352/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 337/1000, Total_RWD: -269.3, Steps: 191/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 338/1000, Total_RWD: 3.5, Steps: 333/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 339/1000, Total_RWD: 189.0, Steps: 1000/4000 e: 0.01, Last_rwd: -0.12555435010396465, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 340/1000, Total_RWD: 204.3, Steps: 690/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 341/1000, Total_RWD: 191.2, Steps: 469/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 342/1000, Total_RWD: 148.6, Steps: 960/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 343/1000, Total_RWD: 263.2, Steps: 305/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 344/1000, Total_RWD: -512.3, Steps: 124/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 345/1000, Total_RWD: -508.3, Steps: 143/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 346/1000, Total_RWD: 269.4, Steps: 433/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 347/1000, Total_RWD: -75.2, Steps: 1000/4000 e: 0.01, Last_rwd: -0.78931667387637, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 348/1000, Total_RWD: 46.2, Steps: 1000/4000 e: 0.01, Last_rwd: -0.47179231727285287, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 349/1000, Total_RWD: -3.5, Steps: 169/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 350/1000, Total_RWD: 274.1, Steps: 225/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "Saving model under:  ./models/DQN_T1604814159_E350.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 351/1000, Total_RWD: 38.2, Steps: 153/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 352/1000, Total_RWD: 276.5, Steps: 255/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 353/1000, Total_RWD: 279.8, Steps: 322/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 354/1000, Total_RWD: -277.6, Steps: 221/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 355/1000, Total_RWD: -359.1, Steps: 159/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 356/1000, Total_RWD: -196.7, Steps: 539/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 357/1000, Total_RWD: 201.6, Steps: 860/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 358/1000, Total_RWD: -262.3, Steps: 1000/4000 e: 0.01, Last_rwd: 1.047773392002398, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 359/1000, Total_RWD: -129.6, Steps: 1000/4000 e: 0.01, Last_rwd: -0.25060197283468993, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 360/1000, Total_RWD: 253.7, Steps: 381/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 361/1000, Total_RWD: -773.5, Steps: 211/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 362/1000, Total_RWD: -57.5, Steps: 325/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 363/1000, Total_RWD: -619.0, Steps: 132/4000 e: 0.01, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 364/1000, Total_RWD: -112.5, Steps: 117/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 365/1000, Total_RWD: -29.9, Steps: 328/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 366/1000, Total_RWD: -58.9, Steps: 371/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 367/1000, Total_RWD: 231.6, Steps: 616/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 368/1000, Total_RWD: 293.5, Steps: 327/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 369/1000, Total_RWD: -198.8, Steps: 1000/4000 e: 0.01, Last_rwd: 2.0740974691305896, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 370/1000, Total_RWD: 11.6, Steps: 253/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 371/1000, Total_RWD: 50.1, Steps: 201/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 372/1000, Total_RWD: 263.9, Steps: 329/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 373/1000, Total_RWD: 272.6, Steps: 302/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 374/1000, Total_RWD: 252.4, Steps: 299/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 375/1000, Total_RWD: 231.8, Steps: 405/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 376/1000, Total_RWD: 226.3, Steps: 428/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 377/1000, Total_RWD: 245.5, Steps: 625/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 378/1000, Total_RWD: 213.6, Steps: 448/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 379/1000, Total_RWD: -522.9, Steps: 121/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 380/1000, Total_RWD: -227.0, Steps: 251/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 381/1000, Total_RWD: 6.0, Steps: 303/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 382/1000, Total_RWD: 216.6, Steps: 562/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 383/1000, Total_RWD: 217.9, Steps: 603/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 384/1000, Total_RWD: 230.4, Steps: 388/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 385/1000, Total_RWD: 17.4, Steps: 249/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 386/1000, Total_RWD: -29.7, Steps: 197/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 387/1000, Total_RWD: -2.1, Steps: 262/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 388/1000, Total_RWD: 222.7, Steps: 400/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 389/1000, Total_RWD: 5.4, Steps: 138/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 390/1000, Total_RWD: 264.5, Steps: 242/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 391/1000, Total_RWD: 11.9, Steps: 142/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 392/1000, Total_RWD: 8.1, Steps: 125/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 393/1000, Total_RWD: -746.8, Steps: 183/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 394/1000, Total_RWD: -178.5, Steps: 150/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 395/1000, Total_RWD: -494.5, Steps: 66/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 396/1000, Total_RWD: -751.3, Steps: 83/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 397/1000, Total_RWD: -458.3, Steps: 62/4000 e: 0.01, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 398/1000, Total_RWD: -358.7, Steps: 50/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 399/1000, Total_RWD: -249.1, Steps: 53/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 400/1000, Total_RWD: -329.2, Steps: 100/4000 e: 0.01, Last_rwd: -100, \n",
      "Saving model under:  ./models/DQN_T1604816910_E400.h5\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 401/1000, Total_RWD: -350.6, Steps: 453/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 402/1000, Total_RWD: -557.7, Steps: 91/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 403/1000, Total_RWD: -415.6, Steps: 134/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 404/1000, Total_RWD: -97.2, Steps: 1000/4000 e: 0.01, Last_rwd: -2.217230633071722, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 405/1000, Total_RWD: -158.7, Steps: 1000/4000 e: 0.01, Last_rwd: 1.3527559003673104, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 406/1000, Total_RWD: -86.6, Steps: 497/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 407/1000, Total_RWD: -250.1, Steps: 1000/4000 e: 0.01, Last_rwd: -2.591236176589393, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 408/1000, Total_RWD: -31.3, Steps: 228/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 409/1000, Total_RWD: -60.9, Steps: 380/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 410/1000, Total_RWD: -246.0, Steps: 461/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 411/1000, Total_RWD: 185.7, Steps: 728/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 412/1000, Total_RWD: 209.6, Steps: 451/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 413/1000, Total_RWD: -14.1, Steps: 386/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 414/1000, Total_RWD: 216.6, Steps: 601/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 415/1000, Total_RWD: 26.3, Steps: 333/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 416/1000, Total_RWD: -43.1, Steps: 379/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 417/1000, Total_RWD: -71.1, Steps: 440/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 418/1000, Total_RWD: -21.7, Steps: 146/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 419/1000, Total_RWD: -33.8, Steps: 1000/4000 e: 0.01, Last_rwd: -1.3333940011318959, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 420/1000, Total_RWD: 277.5, Steps: 695/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 421/1000, Total_RWD: 283.4, Steps: 533/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 422/1000, Total_RWD: 264.9, Steps: 381/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 423/1000, Total_RWD: 27.9, Steps: 238/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 424/1000, Total_RWD: 238.0, Steps: 328/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 425/1000, Total_RWD: 212.7, Steps: 850/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 426/1000, Total_RWD: -29.7, Steps: 1000/4000 e: 0.01, Last_rwd: 1.1915595926608702, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 427/1000, Total_RWD: 240.8, Steps: 420/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 428/1000, Total_RWD: 271.6, Steps: 485/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 429/1000, Total_RWD: 228.6, Steps: 329/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 430/1000, Total_RWD: 196.4, Steps: 883/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 431/1000, Total_RWD: -405.8, Steps: 94/4000 e: 0.01, Last_rwd: -100, \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 432/1000, Total_RWD: 218.4, Steps: 775/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 433/1000, Total_RWD: -390.9, Steps: 66/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 434/1000, Total_RWD: -305.5, Steps: 87/4000 e: 0.01, Last_rwd: -100, \n",
      "\n",
      "Good episodes:  [296.3041177248857, 294.59616694176134, 295.4949628938453] / 3\n",
      "Bad episodes:  [-1635.0678242133074, -1243.0188418614368, -1303.7077796546573] / 3\n",
      "Ep: 435/1000, Total_RWD: 252.5, Steps: 272/4000 e: 0.01, Last_rwd: 100, !! WINNER, WE WON !!\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Balki\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\Balki\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scores = []\n",
    "    EPISODES = 1000\n",
    "    render_every_ep = 1\n",
    "    video_record_every_ep = 1\n",
    "    good_episodes = None\n",
    "    \n",
    "    env = gym.make(\"LunarLander-v2\")\n",
    "    env = gym.wrappers.Monitor(env, \"./videos/\"+str(int(time()))+\"/\", video_callable=lambda episode_id: episode_id%video_record_every_ep==0)\n",
    "    env._max_episode_steps = 4000 # changes the max steps in an episode\n",
    "    \n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "\n",
    "    agent = DQNAgent(state_size, action_size, good_memory=good_episodes)\n",
    "    agent.gamma=0.99         # reward discount rate\n",
    "    agent.epsilon=0.3        # exploration rate\n",
    "    agent.epsilon_min=0.01\n",
    "    agent.epsilon_decay=0.99\n",
    "    agent.batch_size=32\n",
    "    agent.train_start=600   # when we have this many individual memories, the training can start\n",
    "    agent.memory.max_good_episodes = 3\n",
    "    agent.memory.max_bad_episodes = 3\n",
    "    \n",
    "    graph = None#DQNPlotting()\n",
    "    \n",
    "    #agent.load(\"./models/DQN_T1604241703_R57.1_E200.h5\")\n",
    "    scores = run(env=env, \n",
    "                 agent=agent, \n",
    "                 EPISODES=EPISODES, \n",
    "                 render_every_ep=render_every_ep,\n",
    "                 graph=graph,\n",
    "                )\n",
    "    '''\n",
    "    \n",
    "    scores = test(env=env,\n",
    "                  agent=agent,\n",
    "                  EPISODES=EPISODES,\n",
    "                  render_every_ep=render_every_ep,\n",
    "                  graph=graph\n",
    "                  )\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(1,1,figsize=(8,8))\n",
    "ax1.plot(scores)\n",
    "ax1.plot([np.mean(scores[i-100:i]) for i in range(len(scores))])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"good.pickle\", \"wb\") as f:\n",
    "    pickle.dump(good_episodes, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"good.pickle\", \"rb\") as f:\n",
    "    a = pickle.load(f)\n",
    "    \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
